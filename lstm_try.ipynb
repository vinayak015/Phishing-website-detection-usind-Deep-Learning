{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40750\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from string import printable\n",
    "from sklearn.cross_validation import train_test_split\n",
    "df1=pd.read_csv(\"urlset.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain=list(df1['domain'])\n",
    "labels=list(df1['label'])\n",
    "for i in domain:\n",
    "    if i.startswith('\\'') and i.endswith('\\''):\n",
    "        indx=domain.index(i)\n",
    "        i=i.replace('\\'','')\n",
    "        domain[indx]=i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40750\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "#from keras.initializers import glorot_uniform\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "max_len = 75\n",
    "url_int_tokens = [[printable.index(x) + 1 for x in d if x in printable] for d in domain]\n",
    "X = sequence.pad_sequences(url_int_tokens, maxlen=max_len)\n",
    "print(type(X))\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,labels,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phising():\n",
    "    main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "    emb = Embedding(input_dim=100, output_dim=32, input_length=max_len,\n",
    "                        dropout=0.2, W_regularizer=regularizers.l2(1e-4))(main_input)\n",
    "    X = LSTM(32)(emb)\n",
    "    X =  Dropout(0.5)(X)\n",
    "    X = Dense(1, activation='sigmoid', name='output')(X)\n",
    "    model = Model(inputs=[main_input], outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40750\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n",
      "C:\\Users\\40750\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=100, output_dim=32, input_length=75, embeddings_regularizer=<keras.reg...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model=phising()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "71931/71931 [==============================] - 30s 414us/step - loss: 0.5703 - acc: 0.7100\n",
      "Epoch 2/30\n",
      "71931/71931 [==============================] - 27s 381us/step - loss: 0.3931 - acc: 0.8264\n",
      "Epoch 3/30\n",
      "71931/71931 [==============================] - 27s 379us/step - loss: 0.3475 - acc: 0.8512\n",
      "Epoch 4/30\n",
      "71931/71931 [==============================] - 26s 362us/step - loss: 0.3274 - acc: 0.8612\n",
      "Epoch 5/30\n",
      "71931/71931 [==============================] - 25s 354us/step - loss: 0.3102 - acc: 0.8688\n",
      "Epoch 6/30\n",
      "71931/71931 [==============================] - 25s 351us/step - loss: 0.2980 - acc: 0.8766\n",
      "Epoch 7/30\n",
      "71931/71931 [==============================] - 26s 357us/step - loss: 0.2844 - acc: 0.8831\n",
      "Epoch 8/30\n",
      "71931/71931 [==============================] - 25s 351us/step - loss: 0.2733 - acc: 0.8900\n",
      "Epoch 9/30\n",
      "71931/71931 [==============================] - 26s 361us/step - loss: 0.2634 - acc: 0.8941\n",
      "Epoch 10/30\n",
      "71931/71931 [==============================] - 26s 355us/step - loss: 0.2511 - acc: 0.8997\n",
      "Epoch 11/30\n",
      "71931/71931 [==============================] - 25s 353us/step - loss: 0.2447 - acc: 0.9023\n",
      "Epoch 12/30\n",
      "71931/71931 [==============================] - 26s 359us/step - loss: 0.2341 - acc: 0.9082\n",
      "Epoch 13/30\n",
      "71931/71931 [==============================] - 26s 355us/step - loss: 0.2253 - acc: 0.9113\n",
      "Epoch 14/30\n",
      "71931/71931 [==============================] - 26s 360us/step - loss: 0.2175 - acc: 0.9158\n",
      "Epoch 15/30\n",
      "71931/71931 [==============================] - 26s 355us/step - loss: 0.2112 - acc: 0.9181\n",
      "Epoch 16/30\n",
      "71931/71931 [==============================] - 24s 338us/step - loss: 0.2066 - acc: 0.9196\n",
      "Epoch 17/30\n",
      "71931/71931 [==============================] - 24s 335us/step - loss: 0.1997 - acc: 0.9235\n",
      "Epoch 18/30\n",
      "71931/71931 [==============================] - 24s 335us/step - loss: 0.1975 - acc: 0.9243\n",
      "Epoch 19/30\n",
      "71931/71931 [==============================] - 25s 343us/step - loss: 0.1918 - acc: 0.9273\n",
      "Epoch 20/30\n",
      "71931/71931 [==============================] - 25s 353us/step - loss: 0.1871 - acc: 0.9295\n",
      "Epoch 21/30\n",
      "71931/71931 [==============================] - 27s 370us/step - loss: 0.1855 - acc: 0.9296\n",
      "Epoch 22/30\n",
      "71931/71931 [==============================] - 24s 337us/step - loss: 0.1812 - acc: 0.9322\n",
      "Epoch 23/30\n",
      "71931/71931 [==============================] - 24s 330us/step - loss: 0.1789 - acc: 0.9323\n",
      "Epoch 24/30\n",
      "71931/71931 [==============================] - 24s 336us/step - loss: 0.1764 - acc: 0.9329\n",
      "Epoch 25/30\n",
      "71931/71931 [==============================] - 25s 352us/step - loss: 0.1765 - acc: 0.9331\n",
      "Epoch 26/30\n",
      "71931/71931 [==============================] - 25s 353us/step - loss: 0.1730 - acc: 0.9356\n",
      "Epoch 27/30\n",
      "71931/71931 [==============================] - 27s 372us/step - loss: 0.1699 - acc: 0.9368\n",
      "Epoch 28/30\n",
      "71931/71931 [==============================] - 28s 393us/step - loss: 0.1676 - acc: 0.9373\n",
      "Epoch 29/30\n",
      "71931/71931 [==============================] - 27s 369us/step - loss: 0.1652 - acc: 0.9392\n",
      "Epoch 30/30\n",
      "71931/71931 [==============================] - 27s 376us/step - loss: 0.1644 - acc: 0.9393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19b01a54748>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23977/23977 [==============================] - 9s 363us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1605102640738672, 0.9392751386745631]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9775122]]\n",
      "malicious\n"
     ]
    }
   ],
   "source": [
    "def predict(x_input):\n",
    "    #print(x_input)\n",
    "    url_int_tokens_1=[[printable.index(x) + 1 for x in x_input if x in printable]]\n",
    "    #print(url_int_tokens_1)\n",
    "    X_1 = sequence.pad_sequences(url_int_tokens_1, maxlen=max_len)\n",
    "    p = model.predict(X_1)\n",
    "    print(p)\n",
    "    #print(model.predict(X_1))\n",
    "    return \"not_malicious\" if p < 0.6 else \"malicious\"\n",
    "x_input=\"https://lnkd.in/dkk5-Ti\"\n",
    "print(predict(x_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
